{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 读取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('train_content_list.pickle', 'rb') as file:\n",
    "    train_content_list = pickle.load(file)\n",
    "with open('train_label_list.pickle', 'rb') as file:\n",
    "    train_label_list = pickle.load(file)\n",
    "with open('test_content_list.pickle', 'rb') as file:\n",
    "    test_content_list = pickle.load(file)\n",
    "with open('test_label_list.pickle', 'rb') as file:\n",
    "    test_label_list = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 制作词汇表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def getVocabularyList(content_list, vocabulary_size):\n",
    "    allContent_str = ''.join(content_list)\n",
    "    counter = Counter(allContent_str)\n",
    "    vocabulary_list = [k[0] for k in counter.most_common(vocabulary_size)]\n",
    "    return ['PAD'] + vocabulary_list \n",
    "\n",
    "def makeVocabularyFile(content_list, vocabulary_size):\n",
    "    vocabulary_list = getVocabularyList(content_list, vocabulary_size)\n",
    "    with open('vocabulary.txt', 'w', encoding='utf8') as file:\n",
    "        for vocabulary in vocabulary_list:\n",
    "            file.write(vocabulary + '\\n')\n",
    "\n",
    "makeVocabularyFile(train_content_list, 2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 读取词汇表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('vocabulary.txt', encoding='utf8') as file:\n",
    "    vocabulary_list = [k.strip() for k in file.readlines()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2id_dict = dict([(b, a) for a, b in enumerate(vocabulary_list)])\n",
    "content2idList = lambda content : [word2id_dict[word] for word in content if word in word2id_dict]\n",
    "train_idlist_list = [content2idList(content) for content in train_content_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "541"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = 5000 if len(vocabulary_list) > 5000 else len(vocabulary_list)\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "125"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contentLength_list = [len(k) for k in train_content_list]\n",
    "seq_length = max(contentLength_list)\n",
    "seq_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embedding_dim = 64  # 词向量维度\n",
    "num_classes = 4  # 类别数\n",
    "num_filters = 256  # 卷积核数目\n",
    "kernel_size = 5  # 卷积核尺\n",
    "hidden_dim = 128  # 全连接层神经元\n",
    "dropout_keep_prob = 0.5  # dropout保留比例\n",
    "learning_rate = 1e-3  # 学习率\n",
    "batch_size = 32  # 每批训练大小"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.contrib.keras as kr\n",
    "train_X = kr.preprocessing.sequence.pad_sequences(train_idlist_list, seq_length)\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelEncoder = LabelEncoder()\n",
    "train_y = labelEncoder.fit_transform(train_label_list)\n",
    "train_Y = kr.utils.to_categorical(train_y, num_classes)\n",
    "import tensorflow as tf\n",
    "tf.reset_default_graph()\n",
    "X_holder = tf.placeholder(tf.int32, [None, seq_length])\n",
    "Y_holder = tf.placeholder(tf.float32, [None, num_classes])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 搭建神经网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py:497: calling conv1d (from tensorflow.python.ops.nn_ops) with data_format=NHWC is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "`NHWC` for data_format is deprecated, use `NWC` instead\n"
     ]
    }
   ],
   "source": [
    "embedding = tf.get_variable('embedding', [vocab_size, embedding_dim])\n",
    "embedding_inputs = tf.nn.embedding_lookup(embedding, X_holder)\n",
    "conv = tf.layers.conv1d(embedding_inputs, num_filters, kernel_size)\n",
    "max_pooling = tf.reduce_max(conv, reduction_indices=[1])\n",
    "full_connect = tf.layers.dense(max_pooling, hidden_dim)\n",
    "full_connect_dropout = tf.contrib.layers.dropout(full_connect, keep_prob=0.75)\n",
    "full_connect_activate = tf.nn.relu(full_connect_dropout)\n",
    "softmax_before = tf.layers.dense(full_connect_activate, num_classes)\n",
    "predict_Y = tf.nn.softmax(softmax_before)\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits_v2(labels=Y_holder, logits=softmax_before)\n",
    "loss = tf.reduce_mean(cross_entropy)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "train = optimizer.minimize(loss)\n",
    "isCorrect = tf.equal(tf.argmax(Y_holder, 1), tf.argmax(predict_Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(isCorrect, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 参数初始化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "session = tf.Session()\n",
    "session.run(init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step:1 loss:1.3800 accuracy:0.2550\n",
      "step:10 loss:1.2933 accuracy:0.2250\n",
      "step:20 loss:0.9269 accuracy:0.8150\n",
      "step:30 loss:0.4702 accuracy:0.9550\n",
      "step:40 loss:0.1596 accuracy:0.9950\n",
      "step:50 loss:0.0567 accuracy:1.0000\n",
      "step:60 loss:0.0185 accuracy:1.0000\n",
      "step:70 loss:0.0091 accuracy:1.0000\n",
      "step:80 loss:0.0048 accuracy:1.0000\n",
      "step:90 loss:0.0057 accuracy:1.0000\n",
      "step:100 loss:0.0045 accuracy:1.0000\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "with open('test_content_list.pickle', 'rb') as file:\n",
    "    test_content_list = pickle.load(file)\n",
    "with open('test_label_list.pickle', 'rb') as file:\n",
    "    test_label_list = pickle.load(file)\n",
    "test_idlist_list = [content2idList(content) for content in test_content_list]\n",
    "test_X = kr.preprocessing.sequence.pad_sequences(test_idlist_list, seq_length)\n",
    "test_y = labelEncoder.transform(test_label_list)\n",
    "test_Y = kr.utils.to_categorical(test_y, num_classes)\n",
    "\n",
    "import random\n",
    "for i in range(100):\n",
    "    selected_index = random.sample(list(range(len(train_y))), k=batch_size)\n",
    "    batch_X = train_X[selected_index]\n",
    "    batch_Y = train_Y[selected_index]\n",
    "    session.run(train, {X_holder:batch_X, Y_holder:batch_Y})\n",
    "    step = i + 1 \n",
    "    if step % 10 == 0 or step == 1:\n",
    "        selected_index = random.sample(list(range(len(test_y))), k=200)\n",
    "        batch_X = test_X[selected_index]\n",
    "        batch_Y = test_Y[selected_index]\n",
    "        loss_value, accuracy_value = session.run([loss, accuracy], {X_holder:batch_X, Y_holder:batch_Y})\n",
    "        print('step:%d loss:%.4f accuracy:%.4f' %(step, loss_value, accuracy_value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 混淆矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>beierzi</th>\n",
       "      <th>beilaogong</th>\n",
       "      <th>beilaopo</th>\n",
       "      <th>beinver</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>beierzi</th>\n",
       "      <td>94</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beilaogong</th>\n",
       "      <td>0</td>\n",
       "      <td>117</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beilaopo</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>109</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beinver</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            beierzi  beilaogong  beilaopo  beinver\n",
       "beierzi          94           0         0        0\n",
       "beilaogong        0         117         0        0\n",
       "beilaopo          0           0       109        0\n",
       "beinver           0           0         0      108"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def predictAll(test_X, batch_size=100):\n",
    "    predict_value_list = []\n",
    "    for i in range(0, len(test_X), batch_size):\n",
    "        selected_X = test_X[i: i + batch_size]\n",
    "        predict_value = session.run(predict_Y, {X_holder:selected_X})\n",
    "        predict_value_list.extend(predict_value)\n",
    "    return np.array(predict_value_list)\n",
    "\n",
    "Y = predictAll(test_X)\n",
    "y = np.argmax(Y, axis=1)\n",
    "predict_label_list = labelEncoder.inverse_transform(y)\n",
    "pd.DataFrame(confusion_matrix(test_label_list, predict_label_list), \n",
    "             columns=labelEncoder.classes_,\n",
    "             index=labelEncoder.classes_ )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 报告表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>beierzi</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>beilaogong</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>beilaopo</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>beinver</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>总体</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>428</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Label  Precision  Recall   F1  Support\n",
       "0       beierzi        1.0     1.0  1.0       94\n",
       "1    beilaogong        1.0     1.0  1.0      117\n",
       "2      beilaopo        1.0     1.0  1.0      109\n",
       "3       beinver        1.0     1.0  1.0      108\n",
       "999          总体        1.0     1.0  1.0      428"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "def eval_model(y_true, y_pred, labels):\n",
    "    # 计算每个分类的Precision, Recall, f1, support\n",
    "    p, r, f1, s = precision_recall_fscore_support(y_true, y_pred)\n",
    "    # 计算总体的平均Precision, Recall, f1, support\n",
    "    tot_p = np.average(p, weights=s)\n",
    "    tot_r = np.average(r, weights=s)\n",
    "    tot_f1 = np.average(f1, weights=s)\n",
    "    tot_s = np.sum(s)\n",
    "    res1 = pd.DataFrame({\n",
    "        u'Label': labels,\n",
    "        u'Precision': p,\n",
    "        u'Recall': r,\n",
    "        u'F1': f1,\n",
    "        u'Support': s\n",
    "    })\n",
    "    res2 = pd.DataFrame({\n",
    "        u'Label': ['总体'],\n",
    "        u'Precision': [tot_p],\n",
    "        u'Recall': [tot_r],\n",
    "        u'F1': [tot_f1],\n",
    "        u'Support': [tot_s]\n",
    "    })\n",
    "    res2.index = [999]\n",
    "    res = pd.concat([res1, res2])\n",
    "    return res[['Label', 'Precision', 'Recall', 'F1', 'Support']]\n",
    "\n",
    "eval_model(test_label_list, predict_label_list, labelEncoder.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
